{
 "metadata": {
  "name": "",
  "signature": "sha256:f294cc20b03bed72c51762ee142a4d6dcd2cd7e798b6a0f85f2b84e2dce54617"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## \ud130\ubbf8\ub124\uc774\ud130 \ud559\uc2b5 \uc2dc\ud0a4\uae30 - \uae30\uacc4 \ud559\uc2b5\n",
      "[\ucd9c\ucc98](http://www.imaso.co.kr/?doc=v2/ebook/ebook.php)\n",
      "## \ubc30\uacbd\n",
      "* \uc800\uc7a5 \uacf5\uac04\uc758 \ube44\uc6a9 \uac10\uc18c, \ub370\uc774\ud130 \uc99d\uac00\n",
      "* \ub124\ud2b8\uc6cc\ud2b8 \uc131\ub2a5 \ud5a5\uc0c1\n",
      "* \uae30\ubc18 \ud559\ubb38(\ud1b5\uacc4, \ud655\ub960, \ucef4\ud4e8\ud305) \ubc1c\uc804\n",
      "\n",
      "## \ud559\uc2b5 \uc885\ub958\n",
      "* \uc9c0\ub3c4 \ud559\uc2b5(supervised learning)\uc740 \ub370\uc774\ud130\uc5d0 \uc608\uce21\ud558\uace0\uc790 \ud558\ub294 \ubaa9\uc801 \uc18d\uc131(target feature)\uc774 \uc788\uc5b4  \uc608\uce21 \ubaa8\ub378(predictive model)\uc744 \uad6c\ucd95\ud568\n",
      "* \ube44\uc9c0\ub3c4 \ud559\uc2b5(unsupervised learning)\uc740 \ubaa9\uc801 \uc18d\uc131 \uc5c6\uc774 \uae30\uc220 \ubaa8\ub378(descriptive model)\uc744 \uad6c\ucd95\ud568\n",
      "\n",
      "## scikit-learn \uc18c\uac1c\n",
      "* scikit-learn\uc740 2007\ub144 \uad6c\uae00 \uc378\uba38 \ucf54\ub4dc\uc5d0\uc11c \ucc98\uc74c \uad6c\ud604\n",
      "* \ud30c\uc774\uc36c\uc73c\ub85c \uad6c\ud604\ub41c \uac00\uc7a5 \uc720\uba85\ud55c \uae30\uacc4 \ud559\uc2b5 \uc624\ud508 \uc18c\uc2a4 \ub77c\uc774\ube0c\ub7ec\ub9ac\n",
      "* scikit \uc2a4\ud0dd\uc744 \uc0ac\uc6a9\ud558\uace0 \uc788\uae30 \ub54c\ubb38\uc5d0 \ub2e4\ub978 \ub77c\uc774\ube0c\ub7ec\ub9ac\uc640\uc758 \ud638\ud658\uc131\uc774 \ub9e4\uc6b0 \uc88b\uc74c\n",
      "* \ub77c\uc774\ube0c\ub7ec\ub9ac \ub0b4\uc801\uc73c\ub85c\ub294 \ud1b5\uc77c\ub41c \uc778\ud130\ud398\uc774\uc2a4\ub97c \uac00\uc9c0\uace0 \uc788\uae30 \ub54c\ubb38\uc5d0 \ub9e4\uc6b0 \uac04\ub2e8\ud558\uac8c \uc5ec\ub7ec \uae30\ubc95\uc744 \uc801\uc6a9\ud560 \uc218 \uc788\uc5b4 \uc27d\uace0 \ube60\ub974\uac8c \ucd5c\uc0c1\uc758 \uacb0\uacfc\ub97c \uc5bb\uc744 \uc218 \uc788\uc74c\n",
      "\n",
      "## \uad6c\uc870\n",
      " * BaseEstimator \uc0c1\uc18d \ubc1b\uc74c\n",
      " * ClassifierMixin, RegressorMixin, ClusterMixin\ub4e4\uc774 \uc788\uc5b4 \uae30\ubc95\ub4e4\uc740 \uac01\uac01\uc758 \uae30\ubc95\uc758 \ud074\ub798\uc2a4\ub97c \uc0c1\uc18d \ubc1b\uc544 \uad6c\ud604\ud560 \uc218 \uc788\uc74c\n",
      " <img src=\"sklearn.png\">\n",
      " \n",
      " ## \uc608\uc81c\n",
      " iris [\ubd93\uaf43](https://www.google.co.kr/search?q=%EB%B6%93%EA%BD%83&newwindow=1&client=ubuntu&hs=NEw&channel=fs&tbm=isch&tbo=u&source=univ&sa=X&ei=MrezU8TvBYii8AXemILoBA&ved=0CCIQsAQ&biw=1366&bih=620)\n",
      " \n",
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn import datasets\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "# load data\n",
      "iris = datasets.load_iris()\n",
      "print(iris.DESCR)\n",
      "print(iris.target_names)\n",
      "X, y = iris.data, iris.target\n",
      "print(X[100:120, :])\n",
      "print('Size of data : %s' % (X.shape, ))\n",
      "print('Target value : %s' % np.unique(y))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iris Plants Database\n",
        "\n",
        "Notes\n",
        "-----\n",
        "Data Set Characteristics:\n",
        "    :Number of Instances: 150 (50 in each of three classes)\n",
        "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
        "    :Attribute Information:\n",
        "        - sepal length in cm\n",
        "        - sepal width in cm\n",
        "        - petal length in cm\n",
        "        - petal width in cm\n",
        "        - class:\n",
        "                - Iris-Setosa\n",
        "                - Iris-Versicolour\n",
        "                - Iris-Virginica\n",
        "    :Summary Statistics:\n",
        "    ============== ==== ==== ======= ===== ====================\n",
        "                    Min  Max   Mean    SD   Class Correlation\n",
        "    ============== ==== ==== ======= ===== ====================\n",
        "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
        "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
        "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
        "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
        "    ============== ==== ==== ======= ===== ====================\n",
        "    :Missing Attribute Values: None\n",
        "    :Class Distribution: 33.3% for each of 3 classes.\n",
        "    :Creator: R.A. Fisher\n",
        "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
        "    :Date: July, 1988\n",
        "\n",
        "This is a copy of UCI ML iris datasets.\n",
        "http://archive.ics.uci.edu/ml/datasets/Iris\n",
        "\n",
        "The famous Iris database, first used by Sir R.A Fisher\n",
        "\n",
        "This is perhaps the best known database to be found in the\n",
        "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
        "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
        "data set contains 3 classes of 50 instances each, where each class refers to a\n",
        "type of iris plant.  One class is linearly separable from the other 2; the\n",
        "latter are NOT linearly separable from each other.\n",
        "\n",
        "References\n",
        "----------\n",
        "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
        "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
        "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
        "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
        "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
        "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
        "     Structure and Classification Rule for Recognition in Partially Exposed\n",
        "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
        "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
        "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
        "     on Information Theory, May 1972, 431-433.\n",
        "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
        "     conceptual clustering system finds 3 classes in the data.\n",
        "   - Many, many more ...\n",
        "\n",
        "['setosa' 'versicolor' 'virginica']\n",
        "[[ 6.3  3.3  6.   2.5]\n",
        " [ 5.8  2.7  5.1  1.9]\n",
        " [ 7.1  3.   5.9  2.1]\n",
        " [ 6.3  2.9  5.6  1.8]\n",
        " [ 6.5  3.   5.8  2.2]\n",
        " [ 7.6  3.   6.6  2.1]\n",
        " [ 4.9  2.5  4.5  1.7]\n",
        " [ 7.3  2.9  6.3  1.8]\n",
        " [ 6.7  2.5  5.8  1.8]\n",
        " [ 7.2  3.6  6.1  2.5]\n",
        " [ 6.5  3.2  5.1  2. ]\n",
        " [ 6.4  2.7  5.3  1.9]\n",
        " [ 6.8  3.   5.5  2.1]\n",
        " [ 5.7  2.5  5.   2. ]\n",
        " [ 5.8  2.8  5.1  2.4]\n",
        " [ 6.4  3.2  5.3  2.3]\n",
        " [ 6.5  3.   5.5  1.8]\n",
        " [ 7.7  3.8  6.7  2.2]\n",
        " [ 7.7  2.6  6.9  2.3]\n",
        " [ 6.   2.2  5.   1.5]]\n",
        "Size of data : (150, 4)\n",
        "Target value : [0 1 2]\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample = [[6, 4, 5.5, 2],]\n",
      "#sample = [[6, 4, 5, 2],]\n",
      "# try 1.\n",
      "knn = KNeighborsClassifier(n_neighbors=1)\n",
      "knn.fit(X, y)\n",
      "predicted_value = knn.predict(sample)\n",
      "print('Try 1. -----')\n",
      "print(iris.target_names[predicted_value])\n",
      "print(knn.predict_proba(sample))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Try 1. -----\n",
        "['virginica']\n",
        "[[ 0.  0.  1.]]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# try 2.\n",
      "knn = KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
      "knn.fit(X, y)\n",
      "predicted_value = knn.predict(sample)\n",
      "print('Try 2. -----')\n",
      "print(iris.target_names[predicted_value])\n",
      "print(knn.predict_proba(sample))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Try 2. -----\n",
        "['virginica']\n",
        "[[ 0.          0.08888682  0.91111318]]\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "print('Try 3 with GridSearchCV')\n",
      "parameters = {'n_neighbors':(1, 3, 10), 'weights':('uniform', 'distance')}\n",
      "knn_base = KNeighborsClassifier()\n",
      "grid_search = GridSearchCV(knn_base, parameters)\n",
      "grid_search.fit(X, y)\n",
      "print(grid_search)\n",
      "print(grid_search.best_params_)\n",
      "print(grid_search.grid_scores_)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Try 3 with GridSearchCV\n",
        "GridSearchCV(cv=None,\n",
        "       estimator=KNeighborsClassifier(algorithm=auto, leaf_size=30, metric=minkowski,\n",
        "           n_neighbors=5, p=2, weights=uniform),\n",
        "       estimator__algorithm=auto, estimator__leaf_size=30,\n",
        "       estimator__metric=minkowski, estimator__n_neighbors=5,\n",
        "       estimator__p=2, estimator__weights=uniform, fit_params={}, iid=True,\n",
        "       loss_func=None, n_jobs=1,\n",
        "       param_grid={'n_neighbors': (1, 3, 10), 'weights': ('uniform', 'distance')},\n",
        "       pre_dispatch=2*n_jobs, refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)\n",
        "{'n_neighbors': 3, 'weights': 'uniform'}\n",
        "[mean: 0.96000, std: 0.00000, params: {'n_neighbors': 1, 'weights': 'uniform'}, mean: 0.96000, std: 0.00000, params: {'n_neighbors': 1, 'weights': 'distance'}, mean: 0.96667, std: 0.01886, params: {'n_neighbors': 3, 'weights': 'uniform'}, mean: 0.96667, std: 0.01886, params: {'n_neighbors': 3, 'weights': 'distance'}, mean: 0.95333, std: 0.00943, params: {'n_neighbors': 10, 'weights': 'uniform'}, mean: 0.96667, std: 0.02494, params: {'n_neighbors': 10, 'weights': 'distance'}]\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('Try 4 with GridSearchCV and pipeline')\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "## KNN\n",
      "estimators = [('pca', PCA()), ('knn', KNeighborsClassifier())]\n",
      "parameters = {'pca__n_components':(2, 3), 'knn__n_neighbors':(1, 3, 10), 'knn__weights':('uniform', 'distance')}\n",
      "\n",
      "## SVM\n",
      "#estimators = [('pca', PCA()), ('svm', SVC())]\n",
      "#parameters = {'pca__n_components':(2, 3), 'svm__C':(0.4, 1, 1.5, 2, 3)}\n",
      "\n",
      "\n",
      "## LogisticRegression\n",
      "#estimators = [('pca', PCA()), ('lr', LogisticRegression())]\n",
      "#parameters = {'pca__n_components':(2, 3), 'lr__penalty':( 'l1', 'l2')}\n",
      "\n",
      "\n",
      "\n",
      "pipeline = Pipeline(estimators)\n",
      "print(pipeline)\n",
      "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
      "print(\"Performing grid search...\")\n",
      "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
      "grid_search.fit(X, y)\n",
      "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
      "print(\"Best parameters set:\")\n",
      "best_parameters = grid_search.best_estimator_.get_params()\n",
      "for param_name in sorted(parameters.keys()):\n",
      "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
      "print(grid_search.best_estimator_.predict(sample))\n",
      "print(iris.target_names[grid_search.best_estimator_.predict(sample)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Try 4 with GridSearchCV and pipeline\n",
        "Pipeline(knn=KNeighborsClassifier(algorithm=auto, leaf_size=30, metric=minkowski,\n",
        "           n_neighbors=5, p=2, weights=uniform),\n",
        "     knn__algorithm=auto, knn__leaf_size=30, knn__metric=minkowski,\n",
        "     knn__n_neighbors=5, knn__p=2, knn__weights=uniform,\n",
        "     pca=PCA(copy=True, n_components=None, whiten=False), pca__copy=True,\n",
        "     pca__n_components=None, pca__whiten=False)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Performing grid search...\n",
        "('pipeline:', ['pca', 'knn'])\n",
        "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.0s\n",
        "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    0.1s finished\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Best score: 0.973\n",
        "Best parameters set:\n",
        "\tknn__n_neighbors: 3\n",
        "\tknn__weights: 'uniform'\n",
        "\tpca__n_components: 2\n",
        "[2]\n",
        "['virginica']\n"
       ]
      }
     ],
     "prompt_number": 6
    }
   ],
   "metadata": {}
  }
 ]
}